{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praktyczny Machine Learning w Pythonie\n",
    "<br>\n",
    "<img src=\"figures/pie.gif\">\n",
    "\n",
    "## Podstawy machine learningu i scikit-learn\n",
    "\n",
    "Na tych warsztatach skupimy się na modelach liniowych. Modele liniowe odzielają obiekty różnych klas za pomocą linii prostej. Poniższy rysunek powinien to wyjaśnić:\n",
    "\n",
    "<img src=\"figures/twofeature_b.png\">\n",
    "\n",
    "Kółkami są różne obiekty (konkretne irysy, odręcznie napisany cyfry, itp.)\n",
    "Na osi X i Y mamy cechy obiektu (np. długość i szerokość płatków), a linia odziela przykłady różnych klas. Chcąc sklasyfikować **nowy** przykład patrzymy po której znajduje się stronie linii. Proste! A podstawa ogromnej części machine learningu. Jak mamy dobre cechy, to często wystarczy prosta kreska. Dlatego zwykle większość czasu w machine learningu nie jest poświęcane na znajdowanie najlepszego modelu, a zbieranie i czyszczenie danych.\n",
    "\n",
    "## 1. Scikit-learn\n",
    "\n",
    "Scikit-learn to bardzo popularny pakiet udostępniający różne algorytmy uczenia maszynowego. Używany jest w wielu firmach (w tym Microsoft, Evernote, ...). Skupimy się na modelach liniowych. Większość obiektów w scikit-learn implementuje interfejs **Estimator**. Według tej terminologii \"dopasowywujemy\" się do dancyh, aby potem \"przewidzieć\" klasę obiektu.\n",
    "\n",
    "```{python}\n",
    "class Estimator(object):\n",
    "  \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fits estimator to data. \"\"\"\n",
    "        # set state of ``self``\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict response of ``X``. \"\"\"\n",
    "        # compute predictions ``pred``\n",
    "        return pred\n",
    "```\n",
    "\n",
    "**Każdy model to Estimator**, a jest ich bardzo dużo. Dodatkowo (do czego dojdziemy) różne preprocessingi na danych (np skalowanie) też implementują ten interfejs co bardzo upraszcza pracę z pakietem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tworzymy nasz model liniowy odróżniający gatunek irysów Setosa od innych!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardowe importowanie pakietów\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Ładujemy dane. Zapis iris.data[:,0:2] oznacza wybierz 2 pierwsze kolumny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Załadujmy jeszcze raz dane iris\n",
    "iris = load_iris()\n",
    "X,Y = iris.data[:,0:2], iris.target\n",
    "Y = Y==0 # Troche magii żeby przewidywał tylko Iris Setosa albo \"nie Iris Setosa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris.target_names # Setosa jest pierwsza (indeks 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ok! Dopasowywujemy model. \n",
    "from sklearn.svm import LinearSVC\n",
    "# Regresja liniowa. Jeden z wielu modeli, których końcowym wynikiem jest linia prosta :)\n",
    "pierwszy_model = LinearSVC() \n",
    "pierwszy_model.fit(X, Y) # Wspominany interfejs! Po zrobieniu fit mamy linię prostą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pierwszy_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Model machine learningowy (*pierwszy_model* w naszym kodzie) można streścić jako:\n",
    "\n",
    "\"Jeśli -1.541405 \\* **długość_płatka** + 2.28320578 \\* **szerokość_płatka** >= 0 to jest to kwiatek gatunku *Iris Setosa*\"\n",
    "\n",
    "Nie uwierzycie ile modeli jest tak prostych :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Można zapytać (predict w Estimator)\n",
    "pierwszy_model.predict([-0.109, 0.451]) # Kwiatek gatunku Iris Setosa! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Wizualizacja nauczonego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tworzymy siatkę punktów w odstępie 1e-2\n",
    "h = 1e-2\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Przewidujemy\n",
    "Z = pierwszy_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Rysujemy ładny wykres \n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title(\"pierwszy_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podstawy machine learningu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podsumujmy co wiemy:\n",
    "    \n",
    "* Machine Learning zajmuje się tworzeniem modeli, które uczymy na podstawie danych\n",
    "* Scikit-learn udostępnia wiele modeli, uczymy je za pomocą funkcji **fit**, przewidujemy za pomocą funkcji **predict**\n",
    "* Ważną klasą modeli są modele liniowe na których się skupimy\n",
    "* Znamy podstawy numpy i matplotlib\n",
    "\n",
    "Wprowadzimy jeszcze 3 pojęcia:\n",
    "* Testowanie modelu\n",
    "* Preprocessing danych\n",
    "* Hiperparametry\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Testowanie modelu\n",
    "\n",
    "Chcemy wiedzieć jak dobry jest model który mamy. W tym celu zbiór danych dzielimy na ** zbiór trenujący ** i ** zbiór testujący **. Uczymy się na zbiorze trenującym, testujemy na testującym. Zwykle podsumowywujemy wynik modelu jedną liczbą, np. **dokładność** (ang. *accuracy*) czyli ilość procent poprawnie sklasyfikowanych przykładów\n",
    "\n",
    "Przetestujmy jak sobie radzi nasz LogisticRegression na zbiorze Iris. Teraz weźmiemy wszystkie przykłady do nauki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Załadujmy jeszcze raz dane iris\n",
    "iris = load_iris()\n",
    "X,Y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dzielimy (scikit-learn)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Pierwszy przykład trenujący: \", X_train[0], \"Klasa: \", Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drugi_model = LinearSVC(C=10) \n",
    "drugi_model.fit(X_train, Y_train) # Wspominany interfejs! Po zrobieniu fit mamy linię prostą\n",
    "Y_test_predicted = drugi_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Przewidywania na pierwszych 10 przykladach: \", Y_test_predicted[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print \"Dokładność modelu to: \",100*sklearn.metrics.accuracy_score(Y_test, Y_test_predicted), \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ćwiczenie 4: Proszę zamienić LinearSVC na inny model, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Preprocessing danych\n",
    "\n",
    "Wiele modeli lepiej działa na przekształconych danych. Przekształcenia to np.:\n",
    "    \n",
    "    * Normalizacja\n",
    "    * Skalowanie\n",
    "    * Przesunięcie\n",
    "    * Obrót\n",
    "    * Zmniejszenie ilości wymiarów\n",
    "    \n",
    "Skupimy się na ostatnim typie: zmniejszenie ilości wymiarów.\n",
    "    \n",
    "<img src=\"figures/dim-red.jpg\"></img>\n",
    "<img width=\"500\" src=\"figures/Inversion.png\"></img>\n",
    "\n",
    "Zmniejszenie ilości wymiarów (ang. *dimensionality reduction*) to takie przekształcenie,\n",
    "które zmniejsza wymiar danych (ilość cech) gubiąc minimalną ilość informacji.\n",
    "Czasami dane można opisać mniejszą ilością cech (może lepszych!).\n",
    "\n",
    "** Jest to bardzo ważna technika ** ze względu na dużą złożoność algorytmów machine learning (np. SVM z ćwiczenia 4 ma minimalną złożoność ok. O(n^2), w zależności od implementacji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Hiperparametry\n",
    "\n",
    "Każdy model opisywany jest hiperparametrami. Przykładowo w regresji liniowej możemy podać \"fit_intercept\" co oznacza czy linia ma przechodzi przez środek współrzędnych czy nie. Innym parametrem jest C - intuicyjnie opisuje prostote modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ćwiczenie 5: Proszę spróbować zmienić parametr C w LinearSVC tak aby otrzymać 97% dokładności"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
